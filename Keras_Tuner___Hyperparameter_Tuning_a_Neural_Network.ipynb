{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Keras Tuner | Hyperparameter Tuning a Neural Network**"
      ],
      "metadata": {
        "id": "eUDmnmADxa-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Datasets : https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database\n",
        "\n",
        "Colab : https://colab.research.google.com/drive/17M_HtK1wd9U5Qq3TZxcWBhyKqtHHBatQ#scrollTo=6iyw41QtxeSI"
      ],
      "metadata": {
        "id": "6iyw41QtxeSI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6gVfw9hSvsAK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import kerastuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/diabetes.csv')"
      ],
      "metadata": {
        "id": "GmgqVxnfx9mG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fQM3PmfSyBlF",
        "outputId": "80a82241-888a-456e-bd12-d1c3c13b3329"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fb675fa-38fe-4665-b474-4e047b30a6c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fb675fa-38fe-4665-b474-4e047b30a6c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7fb675fa-38fe-4665-b474-4e047b30a6c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7fb675fa-38fe-4665-b474-4e047b30a6c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aff9fa39-05f4-43c1-95a2-a65aa620f17a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aff9fa39-05f4-43c1-95a2-a65aa620f17a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aff9fa39-05f4-43c1-95a2-a65aa620f17a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.884160320375446,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigreeFunction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3313285950127749,\n        \"min\": 0.078,\n        \"max\": 2.42,\n        \"num_unique_values\": 517,\n        \"samples\": [\n          1.731,\n          0.426,\n          0.138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.corr()['Outcome'].sort_values(ascending=True)  # Sorts in ascending order\n",
        "df.corr()['Outcome'].sort_values(ascending=False)  # Sorts in decending order\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "iPdszuy4yHK9",
        "outputId": "4c4c7455-a188-4c3c-a366-e4b552ae35a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Outcome                     1.000000\n",
              "Glucose                     0.466581\n",
              "BMI                         0.292695\n",
              "Age                         0.238356\n",
              "Pregnancies                 0.221898\n",
              "DiabetesPedigreeFunction    0.173844\n",
              "Insulin                     0.130548\n",
              "SkinThickness               0.074752\n",
              "BloodPressure               0.065068\n",
              "Name: Outcome, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Outcome</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glucose</th>\n",
              "      <td>0.466581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>0.292695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0.238356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pregnancies</th>\n",
              "      <td>0.221898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <td>0.173844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Insulin</th>\n",
              "      <td>0.130548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SkinThickness</th>\n",
              "      <td>0.074752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BloodPressure</th>\n",
              "      <td>0.065068</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,:-1].values\n",
        "y = df.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "4cMKywi4yYUU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scaling**"
      ],
      "metadata": {
        "id": "OxT1iS_p13Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()"
      ],
      "metadata": {
        "id": "_0tXCT3izi9B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = sc.fit_transform(X)"
      ],
      "metadata": {
        "id": "PT6-yxqi1D-h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pdvVFZJw2E-h",
        "outputId": "7b30db97-0f70-4b9a-e60c-b5cb280d7a27"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.84488505 -1.12339636 -0.16054575  0.53090156 -0.69289057 -0.68442195\n",
            " -0.36506078 -0.19067191]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2q6s4mIe2OD5",
        "outputId": "15237a64-8534-4fa1-fbcf-72c09677fa0b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "qPTM511mzUy6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "gO8zAnFE2ciZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=8))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VRcZK272zaoS",
        "outputId": "ef8c08fb-b67d-4b34-beea-4d179b8d9c50"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0xb-1BAM2qrx",
        "outputId": "f4b000ce-c040-418c-dfc7-4c21ac3e08a2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5314 - loss: 0.6940 - val_accuracy: 0.6558 - val_loss: 0.6526\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6530 - loss: 0.6441 - val_accuracy: 0.7403 - val_loss: 0.5951\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7498 - loss: 0.5900 - val_accuracy: 0.7403 - val_loss: 0.5503\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7330 - loss: 0.5577 - val_accuracy: 0.7468 - val_loss: 0.5111\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7491 - loss: 0.5321 - val_accuracy: 0.7597 - val_loss: 0.4822\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5246 - val_accuracy: 0.7532 - val_loss: 0.4696\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7865 - loss: 0.4891 - val_accuracy: 0.7532 - val_loss: 0.4560\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7828 - loss: 0.4811 - val_accuracy: 0.7532 - val_loss: 0.4530\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7602 - loss: 0.4829 - val_accuracy: 0.7532 - val_loss: 0.4462\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7928 - loss: 0.4610 - val_accuracy: 0.7727 - val_loss: 0.4432\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7803 - loss: 0.4668 - val_accuracy: 0.7727 - val_loss: 0.4431\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7907 - loss: 0.4500 - val_accuracy: 0.7792 - val_loss: 0.4404\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7734 - loss: 0.4678 - val_accuracy: 0.7857 - val_loss: 0.4404\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7656 - loss: 0.4778 - val_accuracy: 0.7727 - val_loss: 0.4419\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7772 - loss: 0.4587 - val_accuracy: 0.7857 - val_loss: 0.4404\n",
            "Epoch 16/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7874 - loss: 0.4374 - val_accuracy: 0.7922 - val_loss: 0.4390\n",
            "Epoch 17/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7803 - loss: 0.4503 - val_accuracy: 0.7922 - val_loss: 0.4404\n",
            "Epoch 18/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7715 - loss: 0.4543 - val_accuracy: 0.7857 - val_loss: 0.4416\n",
            "Epoch 19/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7885 - loss: 0.4402 - val_accuracy: 0.7857 - val_loss: 0.4401\n",
            "Epoch 20/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7818 - loss: 0.4419 - val_accuracy: 0.7987 - val_loss: 0.4425\n",
            "Epoch 21/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7779 - loss: 0.4620 - val_accuracy: 0.7922 - val_loss: 0.4430\n",
            "Epoch 22/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7812 - loss: 0.4379 - val_accuracy: 0.7922 - val_loss: 0.4389\n",
            "Epoch 23/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7641 - loss: 0.4635 - val_accuracy: 0.8117 - val_loss: 0.4361\n",
            "Epoch 24/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7951 - loss: 0.4365 - val_accuracy: 0.8052 - val_loss: 0.4399\n",
            "Epoch 25/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7691 - loss: 0.4582 - val_accuracy: 0.8052 - val_loss: 0.4453\n",
            "Epoch 26/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8155 - loss: 0.4089 - val_accuracy: 0.8117 - val_loss: 0.4398\n",
            "Epoch 27/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8198 - loss: 0.4353 - val_accuracy: 0.7987 - val_loss: 0.4444\n",
            "Epoch 28/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8013 - loss: 0.4241 - val_accuracy: 0.7987 - val_loss: 0.4454\n",
            "Epoch 29/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.4174 - val_accuracy: 0.7987 - val_loss: 0.4478\n",
            "Epoch 30/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 0.4211 - val_accuracy: 0.8052 - val_loss: 0.4471\n",
            "Epoch 31/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.4463 - val_accuracy: 0.7987 - val_loss: 0.4476\n",
            "Epoch 32/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7823 - loss: 0.4401 - val_accuracy: 0.7922 - val_loss: 0.4499\n",
            "Epoch 33/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.4402 - val_accuracy: 0.8052 - val_loss: 0.4475\n",
            "Epoch 34/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7548 - loss: 0.4705 - val_accuracy: 0.8052 - val_loss: 0.4482\n",
            "Epoch 35/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7952 - loss: 0.4285 - val_accuracy: 0.7987 - val_loss: 0.4525\n",
            "Epoch 36/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4046 - val_accuracy: 0.8052 - val_loss: 0.4473\n",
            "Epoch 37/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.4243 - val_accuracy: 0.8117 - val_loss: 0.4491\n",
            "Epoch 38/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8205 - loss: 0.4225 - val_accuracy: 0.8052 - val_loss: 0.4518\n",
            "Epoch 39/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4238 - val_accuracy: 0.8117 - val_loss: 0.4470\n",
            "Epoch 40/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7951 - loss: 0.4355 - val_accuracy: 0.8117 - val_loss: 0.4490\n",
            "Epoch 41/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7860 - loss: 0.4428 - val_accuracy: 0.7987 - val_loss: 0.4522\n",
            "Epoch 42/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7561 - loss: 0.4904 - val_accuracy: 0.8117 - val_loss: 0.4490\n",
            "Epoch 43/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8043 - loss: 0.4333 - val_accuracy: 0.8117 - val_loss: 0.4483\n",
            "Epoch 44/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8189 - loss: 0.4020 - val_accuracy: 0.7987 - val_loss: 0.4525\n",
            "Epoch 45/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 0.4085 - val_accuracy: 0.8117 - val_loss: 0.4500\n",
            "Epoch 46/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8164 - loss: 0.4151 - val_accuracy: 0.8052 - val_loss: 0.4535\n",
            "Epoch 47/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.4213 - val_accuracy: 0.8052 - val_loss: 0.4537\n",
            "Epoch 48/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8142 - loss: 0.3961 - val_accuracy: 0.8052 - val_loss: 0.4506\n",
            "Epoch 49/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8147 - loss: 0.4350 - val_accuracy: 0.7987 - val_loss: 0.4551\n",
            "Epoch 50/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.4086 - val_accuracy: 0.7922 - val_loss: 0.4520\n",
            "Epoch 51/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8037 - loss: 0.4212 - val_accuracy: 0.7987 - val_loss: 0.4533\n",
            "Epoch 52/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8048 - loss: 0.4072 - val_accuracy: 0.7922 - val_loss: 0.4589\n",
            "Epoch 53/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4306 - val_accuracy: 0.7922 - val_loss: 0.4540\n",
            "Epoch 54/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8233 - loss: 0.4073 - val_accuracy: 0.7987 - val_loss: 0.4549\n",
            "Epoch 55/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8093 - loss: 0.4100 - val_accuracy: 0.7987 - val_loss: 0.4583\n",
            "Epoch 56/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8174 - loss: 0.4199 - val_accuracy: 0.8117 - val_loss: 0.4563\n",
            "Epoch 57/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.4160 - val_accuracy: 0.7922 - val_loss: 0.4570\n",
            "Epoch 58/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.3924 - val_accuracy: 0.7987 - val_loss: 0.4563\n",
            "Epoch 59/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8044 - loss: 0.4400 - val_accuracy: 0.7987 - val_loss: 0.4573\n",
            "Epoch 60/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8145 - loss: 0.3998 - val_accuracy: 0.7987 - val_loss: 0.4573\n",
            "Epoch 61/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.3902 - val_accuracy: 0.7987 - val_loss: 0.4618\n",
            "Epoch 62/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8128 - loss: 0.4051 - val_accuracy: 0.7987 - val_loss: 0.4607\n",
            "Epoch 63/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8277 - loss: 0.4033 - val_accuracy: 0.7987 - val_loss: 0.4597\n",
            "Epoch 64/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8269 - loss: 0.3885 - val_accuracy: 0.7987 - val_loss: 0.4572\n",
            "Epoch 65/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8325 - loss: 0.3859 - val_accuracy: 0.8052 - val_loss: 0.4576\n",
            "Epoch 66/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.4313 - val_accuracy: 0.8117 - val_loss: 0.4634\n",
            "Epoch 67/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.4081 - val_accuracy: 0.7987 - val_loss: 0.4629\n",
            "Epoch 68/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8269 - loss: 0.4181 - val_accuracy: 0.8052 - val_loss: 0.4628\n",
            "Epoch 69/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8134 - loss: 0.4073 - val_accuracy: 0.7987 - val_loss: 0.4606\n",
            "Epoch 70/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.4085 - val_accuracy: 0.8182 - val_loss: 0.4637\n",
            "Epoch 71/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7891 - loss: 0.4304 - val_accuracy: 0.8182 - val_loss: 0.4612\n",
            "Epoch 72/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.4114 - val_accuracy: 0.8117 - val_loss: 0.4701\n",
            "Epoch 73/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8404 - loss: 0.3698 - val_accuracy: 0.7987 - val_loss: 0.4658\n",
            "Epoch 74/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8381 - loss: 0.3947 - val_accuracy: 0.8182 - val_loss: 0.4665\n",
            "Epoch 75/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8521 - loss: 0.3631 - val_accuracy: 0.8052 - val_loss: 0.4672\n",
            "Epoch 76/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8291 - loss: 0.3977 - val_accuracy: 0.8182 - val_loss: 0.4644\n",
            "Epoch 77/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.4003 - val_accuracy: 0.8182 - val_loss: 0.4674\n",
            "Epoch 78/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8306 - loss: 0.3752 - val_accuracy: 0.8182 - val_loss: 0.4659\n",
            "Epoch 79/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8162 - loss: 0.3844 - val_accuracy: 0.8182 - val_loss: 0.4634\n",
            "Epoch 80/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8399 - loss: 0.3723 - val_accuracy: 0.8182 - val_loss: 0.4662\n",
            "Epoch 81/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.4132 - val_accuracy: 0.8182 - val_loss: 0.4648\n",
            "Epoch 82/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8464 - loss: 0.3781 - val_accuracy: 0.8117 - val_loss: 0.4698\n",
            "Epoch 83/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8378 - loss: 0.3860 - val_accuracy: 0.8182 - val_loss: 0.4695\n",
            "Epoch 84/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8189 - loss: 0.3781 - val_accuracy: 0.8182 - val_loss: 0.4722\n",
            "Epoch 85/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8315 - loss: 0.3868 - val_accuracy: 0.8117 - val_loss: 0.4672\n",
            "Epoch 86/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8213 - loss: 0.3865 - val_accuracy: 0.8182 - val_loss: 0.4650\n",
            "Epoch 87/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8375 - loss: 0.3625 - val_accuracy: 0.8182 - val_loss: 0.4702\n",
            "Epoch 88/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8566 - loss: 0.3563 - val_accuracy: 0.7987 - val_loss: 0.4737\n",
            "Epoch 89/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8554 - loss: 0.3814 - val_accuracy: 0.8052 - val_loss: 0.4731\n",
            "Epoch 90/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8560 - loss: 0.3703 - val_accuracy: 0.8052 - val_loss: 0.4766\n",
            "Epoch 91/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8356 - loss: 0.3784 - val_accuracy: 0.7922 - val_loss: 0.4803\n",
            "Epoch 92/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8460 - loss: 0.3478 - val_accuracy: 0.8117 - val_loss: 0.4777\n",
            "Epoch 93/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8437 - loss: 0.3882 - val_accuracy: 0.8052 - val_loss: 0.4784\n",
            "Epoch 94/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8543 - loss: 0.3647 - val_accuracy: 0.7987 - val_loss: 0.4824\n",
            "Epoch 95/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8501 - loss: 0.3664 - val_accuracy: 0.8117 - val_loss: 0.4730\n",
            "Epoch 96/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8380 - loss: 0.3759 - val_accuracy: 0.8117 - val_loss: 0.4817\n",
            "Epoch 97/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8377 - loss: 0.3714 - val_accuracy: 0.8117 - val_loss: 0.4835\n",
            "Epoch 98/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8608 - loss: 0.3603 - val_accuracy: 0.8052 - val_loss: 0.4779\n",
            "Epoch 99/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8529 - loss: 0.3523 - val_accuracy: 0.8117 - val_loss: 0.4843\n",
            "Epoch 100/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8654 - loss: 0.3568 - val_accuracy: 0.7987 - val_loss: 0.4836\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fd0d618f400>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nd2LVR1W2wEV",
        "outputId": "d0f3cda1-97f3-48fd-a738-bcb4533f4e60"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.4890 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4836036264896393, 0.798701286315918]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hyperparameter**"
      ],
      "metadata": {
        "id": "m9EjOr6m3k1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. How to select appropriate optimizer\n",
        "2. No. of nodes in a layer\n",
        "3. How to select no. of hidden layers\n",
        "4. All in all one model"
      ],
      "metadata": {
        "id": "D6zenHTR33ru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kerastuner For Hyper parameter**\n",
        "https://keras.io/keras_tuner/"
      ],
      "metadata": {
        "id": "J5AaCOR94vYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "s3RfxPcT3-8P",
        "outputId": "dcf9cc34-8f48-401b-b2ed-4ac8304d5e4f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kerastuner as kt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vFnW2pk_3iPL",
        "outputId": "84b5d875-480e-415e-8be7-952e64376896"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-5fd8096cdee5>:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  import kerastuner as kt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bulid model on different optimizer**\n",
        "\n",
        "karas optimizer:\n",
        "https://keras.io/api/optimizers/\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Fc0JSWI25gMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32, activation='relu', input_dim=8))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  optimizer=hp.Choice('optimizer',values = ['Adam','RMSprop','NAG','Adagrad',\"Adadelta\",'Rmsprop','Momentum'])\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "JvqrDofV37Xi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tuner object**"
      ],
      "metadata": {
        "id": "ZZ1Fy46X67Dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tunner = kt.RandomSearch(build_model,objective='val_accuracy',max_trials=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xosea01X6aY3",
        "outputId": "7c940363-1c08-4f9c-ed9d-64ba2c7ee552"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tunner.search(X_train,y_train,epochs=25,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qc28BdP67MSJ",
        "outputId": "0be8cd13-bc8a-4eb6-e6be-ca9f07171df5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 05s]\n",
            "val_accuracy: 0.8311688303947449\n",
            "\n",
            "Best val_accuracy So Far: 0.8311688303947449\n",
            "Total elapsed time: 00h 00m 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Tunner**"
      ],
      "metadata": {
        "id": "02foAehJ7hBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tunner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rU0XLGq47UWk",
        "outputId": "cb6ec921-3f62-4b3b-a093-77ed19501130"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'optimizer': 'Rmsprop'}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract model**"
      ],
      "metadata": {
        "id": "Myfkh0h37sh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tunner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1MtDuOVD7nia",
        "outputId": "795dff8d-3ac4-4aee-ce38-9bd6ea0f57e5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 8 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "2nvFIVw97y_G",
        "outputId": "367577ae-1dc2-494a-8d8f-4fb23b7a0b5f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m288\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m833\u001b[0m (3.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">833</span> (3.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m833\u001b[0m (3.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">833</span> (3.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7FYN0keU74Hr",
        "outputId": "9a0628c4-93dc-4989-8cd5-fde7e8d71e70"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7542 - loss: 0.5254 - val_accuracy: 0.8312 - val_loss: 0.4404\n",
            "Epoch 2/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7472 - loss: 0.5165 - val_accuracy: 0.8117 - val_loss: 0.4271\n",
            "Epoch 3/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7795 - loss: 0.4783 - val_accuracy: 0.8117 - val_loss: 0.4177\n",
            "Epoch 4/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7670 - loss: 0.4882 - val_accuracy: 0.8117 - val_loss: 0.4152\n",
            "Epoch 5/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7598 - loss: 0.4685 - val_accuracy: 0.8247 - val_loss: 0.4179\n",
            "Epoch 6/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.5098 - val_accuracy: 0.8052 - val_loss: 0.4130\n",
            "Epoch 7/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7856 - loss: 0.4411 - val_accuracy: 0.8247 - val_loss: 0.4146\n",
            "Epoch 8/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7867 - loss: 0.4481 - val_accuracy: 0.8312 - val_loss: 0.4192\n",
            "Epoch 9/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7717 - loss: 0.4583 - val_accuracy: 0.8312 - val_loss: 0.4225\n",
            "Epoch 10/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.4545 - val_accuracy: 0.8182 - val_loss: 0.4196\n",
            "Epoch 11/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7618 - loss: 0.4658 - val_accuracy: 0.8182 - val_loss: 0.4198\n",
            "Epoch 12/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8043 - loss: 0.4217 - val_accuracy: 0.8182 - val_loss: 0.4218\n",
            "Epoch 13/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7538 - loss: 0.4545 - val_accuracy: 0.8182 - val_loss: 0.4232\n",
            "Epoch 14/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7548 - loss: 0.4679 - val_accuracy: 0.8117 - val_loss: 0.4213\n",
            "Epoch 15/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7798 - loss: 0.4488 - val_accuracy: 0.8182 - val_loss: 0.4241\n",
            "Epoch 16/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.4280 - val_accuracy: 0.8182 - val_loss: 0.4231\n",
            "Epoch 17/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7684 - loss: 0.4624 - val_accuracy: 0.8182 - val_loss: 0.4235\n",
            "Epoch 18/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.4053 - val_accuracy: 0.8052 - val_loss: 0.4217\n",
            "Epoch 19/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7782 - loss: 0.4546 - val_accuracy: 0.8052 - val_loss: 0.4233\n",
            "Epoch 20/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 0.4433 - val_accuracy: 0.7987 - val_loss: 0.4219\n",
            "Epoch 21/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7841 - loss: 0.4338 - val_accuracy: 0.8117 - val_loss: 0.4302\n",
            "Epoch 22/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8119 - loss: 0.3915 - val_accuracy: 0.8182 - val_loss: 0.4287\n",
            "Epoch 23/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7995 - loss: 0.4247 - val_accuracy: 0.8247 - val_loss: 0.4295\n",
            "Epoch 24/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8029 - loss: 0.4230 - val_accuracy: 0.8182 - val_loss: 0.4303\n",
            "Epoch 25/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7875 - loss: 0.4329 - val_accuracy: 0.8117 - val_loss: 0.4313\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fd07753c730>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PNNiZYUU7-iH",
        "outputId": "8cbc77c5-8ba8-4fd7-91e8-354cf71ed4e2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.4297 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4313042461872101, 0.8116883039474487]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Now Find how much dense layer In starting.**"
      ],
      "metadata": {
        "id": "fzP-x0cA8iqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "\n",
        "  unit = hp.Int('units', min_value=8, max_value=512, step=16)\n",
        "  model.add(Dense(units = unit, activation='relu', input_dim=8))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) # We already find rmsprop is best one.\n",
        "  return model"
      ],
      "metadata": {
        "id": "mx1QwKPv8C0j"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tunner = kt.RandomSearch(build_model,objective='val_accuracy',max_trials=5,\n",
        "                         directory = 'mydir')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yaNGPRIP9K6m",
        "outputId": "e0fcdde0-6c12-4cf2-cd54-94c40fc00b6e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tunner.search(X_train,y_train,epochs=50,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OTJBOtq49Piz",
        "outputId": "b2c46d13-e254-4977-8351-d21a00eb0cd2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 10s]\n",
            "val_accuracy: 0.8246753215789795\n",
            "\n",
            "Best val_accuracy So Far: 0.8311688303947449\n",
            "Total elapsed time: 00h 00m 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tunner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HY9V8DiB9a3u",
        "outputId": "ac428f48-e122-47bb-f0bc-887ece47eb7d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'units': 72}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tunner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jpQEXRLv-Jbv",
        "outputId": "bf0577de-7d1b-47eb-ebda-dbc55b51bb45"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 8 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BHsqTrrv-UuM",
        "outputId": "5c7fe1f4-5e4c-45a3-c691-8868e7136804"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7475 - loss: 0.4720 - val_accuracy: 0.8182 - val_loss: 0.4198\n",
            "Epoch 2/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7687 - loss: 0.4535 - val_accuracy: 0.8247 - val_loss: 0.4275\n",
            "Epoch 3/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7632 - loss: 0.4723 - val_accuracy: 0.8117 - val_loss: 0.4198\n",
            "Epoch 4/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7536 - loss: 0.4758 - val_accuracy: 0.8052 - val_loss: 0.4197\n",
            "Epoch 5/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7854 - loss: 0.4442 - val_accuracy: 0.8052 - val_loss: 0.4235\n",
            "Epoch 6/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7693 - loss: 0.4518 - val_accuracy: 0.8052 - val_loss: 0.4229\n",
            "Epoch 7/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7577 - loss: 0.4628 - val_accuracy: 0.7987 - val_loss: 0.4265\n",
            "Epoch 8/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7805 - loss: 0.4458 - val_accuracy: 0.8052 - val_loss: 0.4303\n",
            "Epoch 9/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7795 - loss: 0.4350 - val_accuracy: 0.8052 - val_loss: 0.4285\n",
            "Epoch 10/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8095 - loss: 0.4152 - val_accuracy: 0.8052 - val_loss: 0.4313\n",
            "Epoch 11/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7862 - loss: 0.4339 - val_accuracy: 0.8052 - val_loss: 0.4361\n",
            "Epoch 12/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7781 - loss: 0.4407 - val_accuracy: 0.8052 - val_loss: 0.4363\n",
            "Epoch 13/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.4311 - val_accuracy: 0.8117 - val_loss: 0.4419\n",
            "Epoch 14/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7963 - loss: 0.4112 - val_accuracy: 0.8052 - val_loss: 0.4382\n",
            "Epoch 15/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.4071 - val_accuracy: 0.8117 - val_loss: 0.4390\n",
            "Epoch 16/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7965 - loss: 0.4302 - val_accuracy: 0.8117 - val_loss: 0.4453\n",
            "Epoch 17/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7646 - loss: 0.4441 - val_accuracy: 0.8182 - val_loss: 0.4394\n",
            "Epoch 18/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7717 - loss: 0.4456 - val_accuracy: 0.8117 - val_loss: 0.4375\n",
            "Epoch 19/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7637 - loss: 0.4564 - val_accuracy: 0.8052 - val_loss: 0.4387\n",
            "Epoch 20/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7821 - loss: 0.4397 - val_accuracy: 0.8182 - val_loss: 0.4427\n",
            "Epoch 21/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8082 - loss: 0.4052 - val_accuracy: 0.8182 - val_loss: 0.4453\n",
            "Epoch 22/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8061 - loss: 0.3994 - val_accuracy: 0.8182 - val_loss: 0.4505\n",
            "Epoch 23/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.4360 - val_accuracy: 0.8052 - val_loss: 0.4474\n",
            "Epoch 24/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7927 - loss: 0.4220 - val_accuracy: 0.8052 - val_loss: 0.4517\n",
            "Epoch 25/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8058 - loss: 0.3964 - val_accuracy: 0.8052 - val_loss: 0.4495\n",
            "Epoch 26/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7916 - loss: 0.4348 - val_accuracy: 0.8052 - val_loss: 0.4492\n",
            "Epoch 27/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8243 - loss: 0.3756 - val_accuracy: 0.8247 - val_loss: 0.4519\n",
            "Epoch 28/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8111 - loss: 0.4018 - val_accuracy: 0.8117 - val_loss: 0.4538\n",
            "Epoch 29/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7772 - loss: 0.4499 - val_accuracy: 0.8117 - val_loss: 0.4529\n",
            "Epoch 30/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.4097 - val_accuracy: 0.8052 - val_loss: 0.4593\n",
            "Epoch 31/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8211 - loss: 0.4063 - val_accuracy: 0.8117 - val_loss: 0.4572\n",
            "Epoch 32/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.4072 - val_accuracy: 0.8182 - val_loss: 0.4567\n",
            "Epoch 33/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.3751 - val_accuracy: 0.8117 - val_loss: 0.4604\n",
            "Epoch 34/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8188 - loss: 0.3978 - val_accuracy: 0.8117 - val_loss: 0.4595\n",
            "Epoch 35/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8356 - loss: 0.3713 - val_accuracy: 0.8182 - val_loss: 0.4629\n",
            "Epoch 36/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8262 - loss: 0.3853 - val_accuracy: 0.8117 - val_loss: 0.4666\n",
            "Epoch 37/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8184 - loss: 0.3924 - val_accuracy: 0.8117 - val_loss: 0.4632\n",
            "Epoch 38/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8224 - loss: 0.3941 - val_accuracy: 0.8117 - val_loss: 0.4639\n",
            "Epoch 39/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8231 - loss: 0.3931 - val_accuracy: 0.8117 - val_loss: 0.4661\n",
            "Epoch 40/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8173 - loss: 0.3952 - val_accuracy: 0.8182 - val_loss: 0.4668\n",
            "Epoch 41/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8457 - loss: 0.3654 - val_accuracy: 0.8247 - val_loss: 0.4720\n",
            "Epoch 42/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8301 - loss: 0.3664 - val_accuracy: 0.8182 - val_loss: 0.4698\n",
            "Epoch 43/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8233 - loss: 0.3789 - val_accuracy: 0.8182 - val_loss: 0.4716\n",
            "Epoch 44/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.3824 - val_accuracy: 0.8117 - val_loss: 0.4700\n",
            "Epoch 45/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8250 - loss: 0.3751 - val_accuracy: 0.8052 - val_loss: 0.4741\n",
            "Epoch 46/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8346 - loss: 0.3811 - val_accuracy: 0.8182 - val_loss: 0.4735\n",
            "Epoch 47/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.3698 - val_accuracy: 0.8117 - val_loss: 0.4700\n",
            "Epoch 48/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8429 - loss: 0.3465 - val_accuracy: 0.8117 - val_loss: 0.4753\n",
            "Epoch 49/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8616 - loss: 0.3506 - val_accuracy: 0.7987 - val_loss: 0.4790\n",
            "Epoch 50/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8284 - loss: 0.3681 - val_accuracy: 0.8117 - val_loss: 0.4820\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fd076fa2e30>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GivqMv4g-ZN-",
        "outputId": "d823fb3c-e102-43b0-ba42-f0c53cb7aff4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8461 - loss: 0.4791 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.48195698857307434, 0.8116883039474487]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Number Of Hidden Layers**"
      ],
      "metadata": {
        "id": "TThUoQVv-pxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(72, activation='relu', input_dim=8)) # we already fine 72 is best for starting\n",
        "\n",
        "  #\n",
        "  for i in range(hp.Int('num_layers', min_value=1, max_value=10)):\n",
        "    model.add(Dense(72, activation='relu'))\n",
        "\n",
        "  model.add(Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) # we already find RMSprop is best\n",
        "  return model"
      ],
      "metadata": {
        "id": "RLY3oPLf-ePB"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tunner = kt.RandomSearch(build_model,objective='val_accuracy',max_trials=5,\n",
        "                         directory = 'mydir',\n",
        "                         project_name = 'Hidden_layer_find')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iaHhv4hM_76r",
        "outputId": "b13795d4-d532-4576-bd7f-3ff02a689f35"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tunner.search(X_train,y_train,epochs=50,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ESuP6Ne7ANLl",
        "outputId": "5b83ef6d-b473-4dac-aac9-c6b25a5400a7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 13s]\n",
            "val_accuracy: 0.8116883039474487\n",
            "\n",
            "Best val_accuracy So Far: 0.8376623392105103\n",
            "Total elapsed time: 00h 00m 59s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tunner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DBFy6tcDAQpi",
        "outputId": "97467ef3-ace1-4f82-bf23-7ceb3a14120a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_layers': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tunner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZPzwY_9pA0ZV",
        "outputId": "44e78bf3-abab-4f2b-8902-c5708bb1432c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 8 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JPjEiHK4A81F",
        "outputId": "a937770e-a30d-40ba-9ccd-6e00dcd95b82"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7983 - loss: 0.4354 - val_accuracy: 0.8117 - val_loss: 0.4416\n",
            "Epoch 2/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8212 - loss: 0.3821 - val_accuracy: 0.8247 - val_loss: 0.4513\n",
            "Epoch 3/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7991 - loss: 0.4261 - val_accuracy: 0.8312 - val_loss: 0.4405\n",
            "Epoch 4/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8101 - loss: 0.3913 - val_accuracy: 0.7987 - val_loss: 0.4380\n",
            "Epoch 5/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8251 - loss: 0.3987 - val_accuracy: 0.8182 - val_loss: 0.4513\n",
            "Epoch 6/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.3364 - val_accuracy: 0.8117 - val_loss: 0.4451\n",
            "Epoch 7/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7951 - loss: 0.4312 - val_accuracy: 0.8117 - val_loss: 0.4498\n",
            "Epoch 8/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8217 - loss: 0.3695 - val_accuracy: 0.8247 - val_loss: 0.4501\n",
            "Epoch 9/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.3627 - val_accuracy: 0.8182 - val_loss: 0.4514\n",
            "Epoch 10/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8221 - loss: 0.3832 - val_accuracy: 0.8312 - val_loss: 0.4514\n",
            "Epoch 11/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8250 - loss: 0.3756 - val_accuracy: 0.8052 - val_loss: 0.4671\n",
            "Epoch 12/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8231 - loss: 0.3804 - val_accuracy: 0.8052 - val_loss: 0.4556\n",
            "Epoch 13/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8511 - loss: 0.3546 - val_accuracy: 0.8052 - val_loss: 0.4591\n",
            "Epoch 14/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8233 - loss: 0.3894 - val_accuracy: 0.8312 - val_loss: 0.4612\n",
            "Epoch 15/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.3690 - val_accuracy: 0.7922 - val_loss: 0.4762\n",
            "Epoch 16/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8417 - loss: 0.3675 - val_accuracy: 0.8247 - val_loss: 0.4653\n",
            "Epoch 17/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8398 - loss: 0.3627 - val_accuracy: 0.7987 - val_loss: 0.4733\n",
            "Epoch 18/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8100 - loss: 0.3807 - val_accuracy: 0.8312 - val_loss: 0.4661\n",
            "Epoch 19/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8371 - loss: 0.3911 - val_accuracy: 0.8312 - val_loss: 0.4601\n",
            "Epoch 20/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8453 - loss: 0.3566 - val_accuracy: 0.7987 - val_loss: 0.4750\n",
            "Epoch 21/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8385 - loss: 0.3711 - val_accuracy: 0.8117 - val_loss: 0.4687\n",
            "Epoch 22/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8315 - loss: 0.3697 - val_accuracy: 0.7987 - val_loss: 0.4688\n",
            "Epoch 23/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8278 - loss: 0.3816 - val_accuracy: 0.8052 - val_loss: 0.4736\n",
            "Epoch 24/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8399 - loss: 0.3590 - val_accuracy: 0.8052 - val_loss: 0.4734\n",
            "Epoch 25/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8597 - loss: 0.3238 - val_accuracy: 0.8117 - val_loss: 0.4779\n",
            "Epoch 26/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8622 - loss: 0.3323 - val_accuracy: 0.8052 - val_loss: 0.4730\n",
            "Epoch 27/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8443 - loss: 0.3481 - val_accuracy: 0.8117 - val_loss: 0.4794\n",
            "Epoch 28/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8538 - loss: 0.3553 - val_accuracy: 0.8247 - val_loss: 0.4761\n",
            "Epoch 29/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8584 - loss: 0.3375 - val_accuracy: 0.7922 - val_loss: 0.4904\n",
            "Epoch 30/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8384 - loss: 0.3773 - val_accuracy: 0.7987 - val_loss: 0.4976\n",
            "Epoch 31/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8249 - loss: 0.3707 - val_accuracy: 0.8182 - val_loss: 0.4819\n",
            "Epoch 32/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8463 - loss: 0.3500 - val_accuracy: 0.8117 - val_loss: 0.4777\n",
            "Epoch 33/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8637 - loss: 0.3113 - val_accuracy: 0.7987 - val_loss: 0.4806\n",
            "Epoch 34/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8705 - loss: 0.3129 - val_accuracy: 0.7857 - val_loss: 0.4954\n",
            "Epoch 35/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8666 - loss: 0.3210 - val_accuracy: 0.7987 - val_loss: 0.4964\n",
            "Epoch 36/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8665 - loss: 0.3123 - val_accuracy: 0.7922 - val_loss: 0.5024\n",
            "Epoch 37/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8554 - loss: 0.3217 - val_accuracy: 0.7922 - val_loss: 0.4901\n",
            "Epoch 38/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8748 - loss: 0.3174 - val_accuracy: 0.8182 - val_loss: 0.4995\n",
            "Epoch 39/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8629 - loss: 0.3203 - val_accuracy: 0.7857 - val_loss: 0.5104\n",
            "Epoch 40/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8852 - loss: 0.2866 - val_accuracy: 0.7987 - val_loss: 0.5117\n",
            "Epoch 41/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8593 - loss: 0.3091 - val_accuracy: 0.7922 - val_loss: 0.5035\n",
            "Epoch 42/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 0.3251 - val_accuracy: 0.7727 - val_loss: 0.5290\n",
            "Epoch 43/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8810 - loss: 0.3077 - val_accuracy: 0.7987 - val_loss: 0.5097\n",
            "Epoch 44/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8673 - loss: 0.3190 - val_accuracy: 0.8052 - val_loss: 0.4973\n",
            "Epoch 45/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8845 - loss: 0.3162 - val_accuracy: 0.8052 - val_loss: 0.4993\n",
            "Epoch 46/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8872 - loss: 0.2859 - val_accuracy: 0.7987 - val_loss: 0.5124\n",
            "Epoch 47/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8761 - loss: 0.2875 - val_accuracy: 0.7857 - val_loss: 0.5275\n",
            "Epoch 48/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8702 - loss: 0.3052 - val_accuracy: 0.7922 - val_loss: 0.5142\n",
            "Epoch 49/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8822 - loss: 0.2978 - val_accuracy: 0.7727 - val_loss: 0.5376\n",
            "Epoch 50/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8698 - loss: 0.3076 - val_accuracy: 0.7922 - val_loss: 0.5252\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fd075ae5930>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uk3vcAoLA_PR",
        "outputId": "889d71e4-c0bd-4dde-ff68-fa6361e9813b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8131 - loss: 0.5373 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5251932144165039, 0.7922077775001526]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **All In one**\n",
        "\n",
        "**keras activation :** https://keras.io/api/layers/activations/\n",
        "\n",
        "**keras optimizer :**"
      ],
      "metadata": {
        "id": "FM13ZVCCBm91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import count\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "def build_model(hp):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  counter = 0\n",
        "\n",
        "  for i in range(hp.Int('num_layers', min_value=1, max_value=10)):\n",
        "    if counter == 0:\n",
        "      model.add(\n",
        "          Dense(\n",
        "              hp.Int('units' + str(i), min_value=8, max_value=512, step=16),\n",
        "              activation=hp.Choice('activation' + str(i), values=['relu', 'tanh', 'sigmoid']),\n",
        "              input_dim=8))\n",
        "      model.add(Dropout(hp.Choice('dropout' + str(i), values=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])))\n",
        "    else:\n",
        "      model.add(\n",
        "          Dense(\n",
        "              hp.Int('units' + str(i), min_value=8, max_value=512, step=16),\n",
        "              activation=hp.Choice('activation' + str(i), values=['relu', 'tanh', 'sigmoid']))\n",
        "          )\n",
        "      model.add(Dropout(hp.Choice('dropout' + str(i), values=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])))\n",
        "\n",
        "    counter += 1\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(\n",
        "        optimizer=hp.Choice('optimizer', values=['rmsprop', 'adam', 'nadam','SGD','Loss Scale Optimizer','Lion',\"Ftrl\",'Adafactor','Adamax','Adagrad','Adadelta','AdamW']),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "  return model"
      ],
      "metadata": {
        "id": "O45eLmamBCaL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tunner = kt.RandomSearch(build_model,objective='val_accuracy',max_trials=5,\n",
        "                         directory = 'mydir',\n",
        "                         project_name = 'All_in_one2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gehzaBpEEHEX",
        "outputId": "9c7fee28-215d-403f-8972-260969389f49"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "lWY_ZwmOFU3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tunner.search(X_train,y_train,epochs=50,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I8iKCn-vEgwO",
        "outputId": "3a89d478-14e0-4a4f-f613-07cd04351d72"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 11s]\n",
            "val_accuracy: 0.8246753215789795\n",
            "\n",
            "Best val_accuracy So Far: 0.8246753215789795\n",
            "Total elapsed time: 00h 01m 19s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tunner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SzL2YiJ0Fgj_",
        "outputId": "5ad6b8af-0958-4327-e4f1-f199a5a2b43f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_layers': 1,\n",
              " 'units0': 216,\n",
              " 'activation0': 'relu',\n",
              " 'dropout0': 0.7,\n",
              " 'optimizer': 'adam',\n",
              " 'units1': 8,\n",
              " 'activation1': 'tanh',\n",
              " 'dropout1': 0.9,\n",
              " 'units2': 24,\n",
              " 'activation2': 'relu',\n",
              " 'dropout2': 0.7,\n",
              " 'units3': 472,\n",
              " 'activation3': 'tanh',\n",
              " 'dropout3': 0.1,\n",
              " 'units4': 296,\n",
              " 'activation4': 'sigmoid',\n",
              " 'dropout4': 0.0,\n",
              " 'units5': 360,\n",
              " 'activation5': 'sigmoid',\n",
              " 'dropout5': 0.1,\n",
              " 'units6': 88,\n",
              " 'activation6': 'relu',\n",
              " 'dropout6': 0.7,\n",
              " 'units7': 392,\n",
              " 'activation7': 'relu',\n",
              " 'dropout7': 0.3,\n",
              " 'units8': 328,\n",
              " 'activation8': 'tanh',\n",
              " 'dropout8': 0.6}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tunner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "w-_LFQOAFxcw",
        "outputId": "6763afd1-3c04-4468-d9f2-f146d8c6b61c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=200,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RfKPvbq7F_fC",
        "outputId": "11f2fa7c-7acb-4b80-c4e3-f34a91b951e1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7851 - loss: 0.4631 - val_accuracy: 0.8182 - val_loss: 0.4317\n",
            "Epoch 2/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.4315 - val_accuracy: 0.8182 - val_loss: 0.4317\n",
            "Epoch 3/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7816 - loss: 0.4472 - val_accuracy: 0.8182 - val_loss: 0.4316\n",
            "Epoch 4/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.4441 - val_accuracy: 0.8182 - val_loss: 0.4325\n",
            "Epoch 5/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7626 - loss: 0.4562 - val_accuracy: 0.8117 - val_loss: 0.4363\n",
            "Epoch 6/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7904 - loss: 0.4491 - val_accuracy: 0.8182 - val_loss: 0.4341\n",
            "Epoch 7/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7801 - loss: 0.4667 - val_accuracy: 0.8052 - val_loss: 0.4388\n",
            "Epoch 8/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7699 - loss: 0.4701 - val_accuracy: 0.8052 - val_loss: 0.4368\n",
            "Epoch 9/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7857 - loss: 0.4584 - val_accuracy: 0.8117 - val_loss: 0.4351\n",
            "Epoch 10/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8030 - loss: 0.4318 - val_accuracy: 0.8052 - val_loss: 0.4380\n",
            "Epoch 11/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7784 - loss: 0.4461 - val_accuracy: 0.8052 - val_loss: 0.4371\n",
            "Epoch 12/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7807 - loss: 0.4509 - val_accuracy: 0.8117 - val_loss: 0.4360\n",
            "Epoch 13/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7554 - loss: 0.4928 - val_accuracy: 0.8117 - val_loss: 0.4351\n",
            "Epoch 14/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7660 - loss: 0.4741 - val_accuracy: 0.8117 - val_loss: 0.4371\n",
            "Epoch 15/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7858 - loss: 0.4304 - val_accuracy: 0.8052 - val_loss: 0.4389\n",
            "Epoch 16/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8081 - loss: 0.4164 - val_accuracy: 0.8052 - val_loss: 0.4377\n",
            "Epoch 17/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7775 - loss: 0.4650 - val_accuracy: 0.8117 - val_loss: 0.4370\n",
            "Epoch 18/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7818 - loss: 0.4526 - val_accuracy: 0.8182 - val_loss: 0.4403\n",
            "Epoch 19/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.4393 - val_accuracy: 0.8182 - val_loss: 0.4391\n",
            "Epoch 20/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8014 - loss: 0.4576 - val_accuracy: 0.8182 - val_loss: 0.4395\n",
            "Epoch 21/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7790 - loss: 0.4526 - val_accuracy: 0.8247 - val_loss: 0.4376\n",
            "Epoch 22/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.4410 - val_accuracy: 0.8182 - val_loss: 0.4385\n",
            "Epoch 23/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7642 - loss: 0.4579 - val_accuracy: 0.8182 - val_loss: 0.4384\n",
            "Epoch 24/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.4247 - val_accuracy: 0.8182 - val_loss: 0.4380\n",
            "Epoch 25/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8240 - loss: 0.4158 - val_accuracy: 0.8182 - val_loss: 0.4387\n",
            "Epoch 26/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7954 - loss: 0.4254 - val_accuracy: 0.8182 - val_loss: 0.4402\n",
            "Epoch 27/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7528 - loss: 0.4590 - val_accuracy: 0.8182 - val_loss: 0.4413\n",
            "Epoch 28/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7818 - loss: 0.4725 - val_accuracy: 0.8182 - val_loss: 0.4422\n",
            "Epoch 29/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8082 - loss: 0.4325 - val_accuracy: 0.8182 - val_loss: 0.4409\n",
            "Epoch 30/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7995 - loss: 0.4183 - val_accuracy: 0.8117 - val_loss: 0.4432\n",
            "Epoch 31/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.4447 - val_accuracy: 0.8117 - val_loss: 0.4411\n",
            "Epoch 32/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.4246 - val_accuracy: 0.8182 - val_loss: 0.4428\n",
            "Epoch 33/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7804 - loss: 0.4476 - val_accuracy: 0.8117 - val_loss: 0.4438\n",
            "Epoch 34/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.4051 - val_accuracy: 0.8117 - val_loss: 0.4423\n",
            "Epoch 35/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4079 - val_accuracy: 0.8117 - val_loss: 0.4406\n",
            "Epoch 36/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7878 - loss: 0.4463 - val_accuracy: 0.8182 - val_loss: 0.4450\n",
            "Epoch 37/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7633 - loss: 0.4586 - val_accuracy: 0.8182 - val_loss: 0.4448\n",
            "Epoch 38/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7962 - loss: 0.4494 - val_accuracy: 0.8117 - val_loss: 0.4437\n",
            "Epoch 39/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7812 - loss: 0.4499 - val_accuracy: 0.8182 - val_loss: 0.4455\n",
            "Epoch 40/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8032 - loss: 0.4449 - val_accuracy: 0.8182 - val_loss: 0.4466\n",
            "Epoch 41/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7925 - loss: 0.4177 - val_accuracy: 0.8182 - val_loss: 0.4462\n",
            "Epoch 42/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.4516 - val_accuracy: 0.8117 - val_loss: 0.4471\n",
            "Epoch 43/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7807 - loss: 0.4493 - val_accuracy: 0.8182 - val_loss: 0.4462\n",
            "Epoch 44/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7920 - loss: 0.4333 - val_accuracy: 0.8117 - val_loss: 0.4466\n",
            "Epoch 45/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4172 - val_accuracy: 0.8182 - val_loss: 0.4445\n",
            "Epoch 46/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.4583 - val_accuracy: 0.8117 - val_loss: 0.4444\n",
            "Epoch 47/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7959 - loss: 0.4177 - val_accuracy: 0.8182 - val_loss: 0.4465\n",
            "Epoch 48/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7975 - loss: 0.4240 - val_accuracy: 0.8182 - val_loss: 0.4455\n",
            "Epoch 49/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.4288 - val_accuracy: 0.8182 - val_loss: 0.4459\n",
            "Epoch 50/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7946 - loss: 0.4403 - val_accuracy: 0.8182 - val_loss: 0.4478\n",
            "Epoch 51/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7960 - loss: 0.4654 - val_accuracy: 0.8117 - val_loss: 0.4495\n",
            "Epoch 52/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8002 - loss: 0.4545 - val_accuracy: 0.8117 - val_loss: 0.4482\n",
            "Epoch 53/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7909 - loss: 0.4449 - val_accuracy: 0.8117 - val_loss: 0.4467\n",
            "Epoch 54/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8231 - loss: 0.4011 - val_accuracy: 0.8052 - val_loss: 0.4484\n",
            "Epoch 55/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8048 - loss: 0.4262 - val_accuracy: 0.7987 - val_loss: 0.4488\n",
            "Epoch 56/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7916 - loss: 0.4169 - val_accuracy: 0.8117 - val_loss: 0.4472\n",
            "Epoch 57/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8222 - loss: 0.4086 - val_accuracy: 0.8117 - val_loss: 0.4465\n",
            "Epoch 58/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.4021 - val_accuracy: 0.8182 - val_loss: 0.4465\n",
            "Epoch 59/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.4157 - val_accuracy: 0.8182 - val_loss: 0.4478\n",
            "Epoch 60/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.4168 - val_accuracy: 0.8182 - val_loss: 0.4471\n",
            "Epoch 61/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8004 - loss: 0.4341 - val_accuracy: 0.8052 - val_loss: 0.4491\n",
            "Epoch 62/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7662 - loss: 0.4823 - val_accuracy: 0.8182 - val_loss: 0.4507\n",
            "Epoch 63/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8055 - loss: 0.4583 - val_accuracy: 0.8052 - val_loss: 0.4496\n",
            "Epoch 64/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.4285 - val_accuracy: 0.8182 - val_loss: 0.4469\n",
            "Epoch 65/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8108 - loss: 0.4196 - val_accuracy: 0.8117 - val_loss: 0.4470\n",
            "Epoch 66/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4326 - val_accuracy: 0.8117 - val_loss: 0.4489\n",
            "Epoch 67/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7742 - loss: 0.4823 - val_accuracy: 0.8052 - val_loss: 0.4476\n",
            "Epoch 68/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7818 - loss: 0.4628 - val_accuracy: 0.8117 - val_loss: 0.4467\n",
            "Epoch 69/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7927 - loss: 0.4295 - val_accuracy: 0.8117 - val_loss: 0.4467\n",
            "Epoch 70/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7981 - loss: 0.4111 - val_accuracy: 0.8117 - val_loss: 0.4475\n",
            "Epoch 71/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.4439 - val_accuracy: 0.8117 - val_loss: 0.4479\n",
            "Epoch 72/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7797 - loss: 0.4764 - val_accuracy: 0.8117 - val_loss: 0.4448\n",
            "Epoch 73/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7865 - loss: 0.4408 - val_accuracy: 0.8182 - val_loss: 0.4466\n",
            "Epoch 74/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8014 - loss: 0.4280 - val_accuracy: 0.8117 - val_loss: 0.4468\n",
            "Epoch 75/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 0.4356 - val_accuracy: 0.8117 - val_loss: 0.4501\n",
            "Epoch 76/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8008 - loss: 0.4304 - val_accuracy: 0.8182 - val_loss: 0.4491\n",
            "Epoch 77/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8049 - loss: 0.4078 - val_accuracy: 0.8182 - val_loss: 0.4503\n",
            "Epoch 78/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7832 - loss: 0.4756 - val_accuracy: 0.8182 - val_loss: 0.4498\n",
            "Epoch 79/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4387 - val_accuracy: 0.8247 - val_loss: 0.4478\n",
            "Epoch 80/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.4661 - val_accuracy: 0.8117 - val_loss: 0.4492\n",
            "Epoch 81/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8018 - loss: 0.4421 - val_accuracy: 0.8182 - val_loss: 0.4492\n",
            "Epoch 82/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.4128 - val_accuracy: 0.8247 - val_loss: 0.4504\n",
            "Epoch 83/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7764 - loss: 0.4799 - val_accuracy: 0.8182 - val_loss: 0.4506\n",
            "Epoch 84/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.4300 - val_accuracy: 0.8182 - val_loss: 0.4507\n",
            "Epoch 85/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.4310 - val_accuracy: 0.8182 - val_loss: 0.4505\n",
            "Epoch 86/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 0.4553 - val_accuracy: 0.8117 - val_loss: 0.4500\n",
            "Epoch 87/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.4903 - val_accuracy: 0.8247 - val_loss: 0.4526\n",
            "Epoch 88/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7960 - loss: 0.4313 - val_accuracy: 0.8117 - val_loss: 0.4522\n",
            "Epoch 89/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7973 - loss: 0.4233 - val_accuracy: 0.8117 - val_loss: 0.4503\n",
            "Epoch 90/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7987 - loss: 0.4328 - val_accuracy: 0.8247 - val_loss: 0.4520\n",
            "Epoch 91/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8103 - loss: 0.4205 - val_accuracy: 0.8117 - val_loss: 0.4479\n",
            "Epoch 92/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7899 - loss: 0.4532 - val_accuracy: 0.8117 - val_loss: 0.4501\n",
            "Epoch 93/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7893 - loss: 0.4179 - val_accuracy: 0.8117 - val_loss: 0.4498\n",
            "Epoch 94/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7896 - loss: 0.4505 - val_accuracy: 0.8117 - val_loss: 0.4510\n",
            "Epoch 95/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8013 - loss: 0.4361 - val_accuracy: 0.8247 - val_loss: 0.4521\n",
            "Epoch 96/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7894 - loss: 0.4181 - val_accuracy: 0.8182 - val_loss: 0.4515\n",
            "Epoch 97/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7879 - loss: 0.4361 - val_accuracy: 0.8117 - val_loss: 0.4538\n",
            "Epoch 98/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8030 - loss: 0.4208 - val_accuracy: 0.8182 - val_loss: 0.4551\n",
            "Epoch 99/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8057 - loss: 0.4348 - val_accuracy: 0.8247 - val_loss: 0.4526\n",
            "Epoch 100/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.4053 - val_accuracy: 0.8312 - val_loss: 0.4533\n",
            "Epoch 101/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7979 - loss: 0.4418 - val_accuracy: 0.8247 - val_loss: 0.4524\n",
            "Epoch 102/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8154 - loss: 0.4390 - val_accuracy: 0.8117 - val_loss: 0.4490\n",
            "Epoch 103/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7718 - loss: 0.4534 - val_accuracy: 0.8182 - val_loss: 0.4510\n",
            "Epoch 104/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.4070 - val_accuracy: 0.8182 - val_loss: 0.4535\n",
            "Epoch 105/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8325 - loss: 0.3925 - val_accuracy: 0.8182 - val_loss: 0.4521\n",
            "Epoch 106/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7963 - loss: 0.4592 - val_accuracy: 0.8117 - val_loss: 0.4512\n",
            "Epoch 107/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.4584 - val_accuracy: 0.8182 - val_loss: 0.4506\n",
            "Epoch 108/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8251 - loss: 0.4183 - val_accuracy: 0.8117 - val_loss: 0.4489\n",
            "Epoch 109/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7886 - loss: 0.4221 - val_accuracy: 0.8247 - val_loss: 0.4505\n",
            "Epoch 110/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7928 - loss: 0.4409 - val_accuracy: 0.8182 - val_loss: 0.4513\n",
            "Epoch 111/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8204 - loss: 0.4161 - val_accuracy: 0.8182 - val_loss: 0.4511\n",
            "Epoch 112/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 0.4310 - val_accuracy: 0.8182 - val_loss: 0.4512\n",
            "Epoch 113/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7970 - loss: 0.4198 - val_accuracy: 0.8182 - val_loss: 0.4538\n",
            "Epoch 114/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8044 - loss: 0.4050 - val_accuracy: 0.8247 - val_loss: 0.4523\n",
            "Epoch 115/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.4502 - val_accuracy: 0.8247 - val_loss: 0.4516\n",
            "Epoch 116/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8306 - loss: 0.3719 - val_accuracy: 0.8182 - val_loss: 0.4512\n",
            "Epoch 117/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7687 - loss: 0.4399 - val_accuracy: 0.8117 - val_loss: 0.4533\n",
            "Epoch 118/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7738 - loss: 0.4594 - val_accuracy: 0.8182 - val_loss: 0.4544\n",
            "Epoch 119/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7969 - loss: 0.4393 - val_accuracy: 0.8117 - val_loss: 0.4528\n",
            "Epoch 120/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8015 - loss: 0.4181 - val_accuracy: 0.8117 - val_loss: 0.4539\n",
            "Epoch 121/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 0.4468 - val_accuracy: 0.8247 - val_loss: 0.4544\n",
            "Epoch 122/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7885 - loss: 0.4632 - val_accuracy: 0.8247 - val_loss: 0.4557\n",
            "Epoch 123/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8190 - loss: 0.3933 - val_accuracy: 0.8247 - val_loss: 0.4539\n",
            "Epoch 124/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8357 - loss: 0.3934 - val_accuracy: 0.8182 - val_loss: 0.4530\n",
            "Epoch 125/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7693 - loss: 0.4441 - val_accuracy: 0.8117 - val_loss: 0.4551\n",
            "Epoch 126/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8125 - loss: 0.4189 - val_accuracy: 0.8182 - val_loss: 0.4539\n",
            "Epoch 127/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.4281 - val_accuracy: 0.8182 - val_loss: 0.4535\n",
            "Epoch 128/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7875 - loss: 0.4441 - val_accuracy: 0.8117 - val_loss: 0.4536\n",
            "Epoch 129/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8179 - loss: 0.4063 - val_accuracy: 0.8182 - val_loss: 0.4539\n",
            "Epoch 130/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.4384 - val_accuracy: 0.8182 - val_loss: 0.4555\n",
            "Epoch 131/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.4263 - val_accuracy: 0.8117 - val_loss: 0.4563\n",
            "Epoch 132/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4391 - val_accuracy: 0.8117 - val_loss: 0.4560\n",
            "Epoch 133/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8184 - loss: 0.4280 - val_accuracy: 0.8182 - val_loss: 0.4560\n",
            "Epoch 134/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4167 - val_accuracy: 0.8182 - val_loss: 0.4560\n",
            "Epoch 135/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7983 - loss: 0.4215 - val_accuracy: 0.8117 - val_loss: 0.4551\n",
            "Epoch 136/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 0.4125 - val_accuracy: 0.8117 - val_loss: 0.4562\n",
            "Epoch 137/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.4198 - val_accuracy: 0.8182 - val_loss: 0.4603\n",
            "Epoch 138/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8135 - loss: 0.4310 - val_accuracy: 0.8182 - val_loss: 0.4589\n",
            "Epoch 139/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8078 - loss: 0.4329 - val_accuracy: 0.8117 - val_loss: 0.4601\n",
            "Epoch 140/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4286 - val_accuracy: 0.8182 - val_loss: 0.4596\n",
            "Epoch 141/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7756 - loss: 0.4293 - val_accuracy: 0.8182 - val_loss: 0.4575\n",
            "Epoch 142/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8273 - loss: 0.3956 - val_accuracy: 0.8182 - val_loss: 0.4557\n",
            "Epoch 143/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8194 - loss: 0.4164 - val_accuracy: 0.8182 - val_loss: 0.4573\n",
            "Epoch 144/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8142 - loss: 0.4166 - val_accuracy: 0.8182 - val_loss: 0.4573\n",
            "Epoch 145/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.4354 - val_accuracy: 0.8117 - val_loss: 0.4586\n",
            "Epoch 146/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.4194 - val_accuracy: 0.8117 - val_loss: 0.4582\n",
            "Epoch 147/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4029 - val_accuracy: 0.8117 - val_loss: 0.4607\n",
            "Epoch 148/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.4194 - val_accuracy: 0.8182 - val_loss: 0.4565\n",
            "Epoch 149/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7914 - loss: 0.4156 - val_accuracy: 0.8182 - val_loss: 0.4554\n",
            "Epoch 150/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7768 - loss: 0.4340 - val_accuracy: 0.8117 - val_loss: 0.4576\n",
            "Epoch 151/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7878 - loss: 0.4281 - val_accuracy: 0.8182 - val_loss: 0.4575\n",
            "Epoch 152/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7942 - loss: 0.4110 - val_accuracy: 0.8182 - val_loss: 0.4567\n",
            "Epoch 153/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8202 - loss: 0.4052 - val_accuracy: 0.8117 - val_loss: 0.4567\n",
            "Epoch 154/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7872 - loss: 0.4421 - val_accuracy: 0.8182 - val_loss: 0.4577\n",
            "Epoch 155/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7840 - loss: 0.4295 - val_accuracy: 0.8117 - val_loss: 0.4567\n",
            "Epoch 156/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7985 - loss: 0.4138 - val_accuracy: 0.8182 - val_loss: 0.4593\n",
            "Epoch 157/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.4049 - val_accuracy: 0.8117 - val_loss: 0.4588\n",
            "Epoch 158/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8275 - loss: 0.4029 - val_accuracy: 0.8182 - val_loss: 0.4571\n",
            "Epoch 159/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7840 - loss: 0.4385 - val_accuracy: 0.8247 - val_loss: 0.4553\n",
            "Epoch 160/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8140 - loss: 0.4134 - val_accuracy: 0.8117 - val_loss: 0.4540\n",
            "Epoch 161/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.4198 - val_accuracy: 0.8117 - val_loss: 0.4540\n",
            "Epoch 162/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.4310 - val_accuracy: 0.8117 - val_loss: 0.4535\n",
            "Epoch 163/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8425 - loss: 0.3799 - val_accuracy: 0.8052 - val_loss: 0.4529\n",
            "Epoch 164/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8228 - loss: 0.3975 - val_accuracy: 0.8117 - val_loss: 0.4565\n",
            "Epoch 165/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8123 - loss: 0.4126 - val_accuracy: 0.8182 - val_loss: 0.4583\n",
            "Epoch 166/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.4202 - val_accuracy: 0.8247 - val_loss: 0.4579\n",
            "Epoch 167/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.4157 - val_accuracy: 0.8117 - val_loss: 0.4567\n",
            "Epoch 168/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8154 - loss: 0.4055 - val_accuracy: 0.8117 - val_loss: 0.4558\n",
            "Epoch 169/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7874 - loss: 0.4527 - val_accuracy: 0.8052 - val_loss: 0.4540\n",
            "Epoch 170/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7885 - loss: 0.4089 - val_accuracy: 0.8052 - val_loss: 0.4545\n",
            "Epoch 171/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8321 - loss: 0.3947 - val_accuracy: 0.7987 - val_loss: 0.4543\n",
            "Epoch 172/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.4174 - val_accuracy: 0.8117 - val_loss: 0.4579\n",
            "Epoch 173/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 0.3880 - val_accuracy: 0.8117 - val_loss: 0.4584\n",
            "Epoch 174/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8151 - loss: 0.3979 - val_accuracy: 0.8052 - val_loss: 0.4568\n",
            "Epoch 175/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8192 - loss: 0.4179 - val_accuracy: 0.7987 - val_loss: 0.4555\n",
            "Epoch 176/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8082 - loss: 0.4204 - val_accuracy: 0.8052 - val_loss: 0.4583\n",
            "Epoch 177/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8151 - loss: 0.4117 - val_accuracy: 0.8182 - val_loss: 0.4573\n",
            "Epoch 178/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8357 - loss: 0.3948 - val_accuracy: 0.8117 - val_loss: 0.4597\n",
            "Epoch 179/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7957 - loss: 0.4191 - val_accuracy: 0.8117 - val_loss: 0.4597\n",
            "Epoch 180/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8329 - loss: 0.3959 - val_accuracy: 0.8247 - val_loss: 0.4599\n",
            "Epoch 181/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8190 - loss: 0.3975 - val_accuracy: 0.8247 - val_loss: 0.4614\n",
            "Epoch 182/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8040 - loss: 0.4406 - val_accuracy: 0.8052 - val_loss: 0.4602\n",
            "Epoch 183/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7900 - loss: 0.4129 - val_accuracy: 0.8052 - val_loss: 0.4618\n",
            "Epoch 184/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8040 - loss: 0.4291 - val_accuracy: 0.7987 - val_loss: 0.4634\n",
            "Epoch 185/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8123 - loss: 0.4150 - val_accuracy: 0.8247 - val_loss: 0.4645\n",
            "Epoch 186/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8201 - loss: 0.3913 - val_accuracy: 0.8182 - val_loss: 0.4660\n",
            "Epoch 187/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7956 - loss: 0.4357 - val_accuracy: 0.7922 - val_loss: 0.4666\n",
            "Epoch 188/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7970 - loss: 0.4169 - val_accuracy: 0.7987 - val_loss: 0.4652\n",
            "Epoch 189/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8344 - loss: 0.3684 - val_accuracy: 0.7987 - val_loss: 0.4652\n",
            "Epoch 190/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.4039 - val_accuracy: 0.8052 - val_loss: 0.4660\n",
            "Epoch 191/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8131 - loss: 0.4209 - val_accuracy: 0.8052 - val_loss: 0.4657\n",
            "Epoch 192/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8118 - loss: 0.4174 - val_accuracy: 0.7987 - val_loss: 0.4632\n",
            "Epoch 193/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8134 - loss: 0.3977 - val_accuracy: 0.7987 - val_loss: 0.4606\n",
            "Epoch 194/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.4373 - val_accuracy: 0.7987 - val_loss: 0.4607\n",
            "Epoch 195/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.3934 - val_accuracy: 0.7987 - val_loss: 0.4607\n",
            "Epoch 196/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.4233 - val_accuracy: 0.7987 - val_loss: 0.4629\n",
            "Epoch 197/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8157 - loss: 0.4090 - val_accuracy: 0.8052 - val_loss: 0.4604\n",
            "Epoch 198/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7923 - loss: 0.4582 - val_accuracy: 0.8052 - val_loss: 0.4601\n",
            "Epoch 199/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8343 - loss: 0.3911 - val_accuracy: 0.8247 - val_loss: 0.4643\n",
            "Epoch 200/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.3979 - val_accuracy: 0.8182 - val_loss: 0.4626\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c208a2150c0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "X5AIwkLVGGPH",
        "outputId": "cda495d2-6707-4e12-d74c-f0b0c47cb6bf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.4667 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4626128077507019, 0.8181818127632141]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7teg1UL1I4KU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}